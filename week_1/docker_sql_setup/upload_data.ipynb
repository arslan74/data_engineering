{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21f9b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cf13ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"postgresql://root:root@localhost:5432/ny_taxi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c3a4d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"yellow_tripdata_2021-01.csv\", nrows = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "001d17e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TEXT, \n",
      "\ttpep_dropoff_datetime TEXT, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(data , \"yellow_taxi_data\" , con = engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff096d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2021-01-01 00:30:10\n",
       "1    2021-01-01 00:51:20\n",
       "2    2021-01-01 00:43:30\n",
       "3    2021-01-01 00:15:48\n",
       "4    2021-01-01 00:31:49\n",
       "             ...        \n",
       "95   2021-01-01 00:12:41\n",
       "96   2021-01-01 00:23:29\n",
       "97   2021-01-01 00:46:17\n",
       "98   2021-01-01 00:28:16\n",
       "99   2021-01-01 00:42:35\n",
       "Name: tpep_pickup_datetime, Length: 100, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(data.tpep_pickup_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0d5eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tpep_pickup_datetime\"] = pd.to_datetime(data.tpep_pickup_datetime)\n",
    "data[\"tpep_dropoff_datetime\"] = pd.to_datetime(data.tpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cfbc69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"yellow_taxi_data\" (\n",
      "\"VendorID\" INTEGER,\n",
      "  \"tpep_pickup_datetime\" TIMESTAMP,\n",
      "  \"tpep_dropoff_datetime\" TIMESTAMP,\n",
      "  \"passenger_count\" INTEGER,\n",
      "  \"trip_distance\" REAL,\n",
      "  \"RatecodeID\" INTEGER,\n",
      "  \"store_and_fwd_flag\" TEXT,\n",
      "  \"PULocationID\" INTEGER,\n",
      "  \"DOLocationID\" INTEGER,\n",
      "  \"payment_type\" INTEGER,\n",
      "  \"fare_amount\" REAL,\n",
      "  \"extra\" REAL,\n",
      "  \"mta_tax\" REAL,\n",
      "  \"tip_amount\" REAL,\n",
      "  \"tolls_amount\" REAL,\n",
      "  \"improvement_surcharge\" REAL,\n",
      "  \"total_amount\" REAL,\n",
      "  \"congestion_surcharge\" REAL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(data , \"yellow_taxi_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8aae20ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iterator = pd.read_csv(\"yellow_tripdata_2021-01.csv\", iterator = True ,chunksize = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bd1522a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.parsers.readers.TextFileReader at 0x7f4302014be0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5198e557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = next(df_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "abe8ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(n = 0).to_sql(name = \"yellow_taxi_data\", con = engine ,if_exists= 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cccbb87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 463 ms, sys: 3.39 ms, total: 467 ms\n",
      "Wall time: 946 ms\n"
     ]
    }
   ],
   "source": [
    "%time data.to_sql(name = \"yellow_taxi_data\", con = engine ,if_exists= 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad2cd197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk...... took 0.920 seconf\n",
      "inserted another chunk...... took 0.870 seconf\n",
      "inserted another chunk...... took 0.942 seconf\n",
      "inserted another chunk...... took 0.989 seconf\n",
      "inserted another chunk...... took 1.133 seconf\n",
      "inserted another chunk...... took 1.022 seconf\n",
      "inserted another chunk...... took 1.387 seconf\n",
      "inserted another chunk...... took 1.120 seconf\n",
      "inserted another chunk...... took 1.002 seconf\n",
      "inserted another chunk...... took 1.036 seconf\n",
      "inserted another chunk...... took 0.855 seconf\n",
      "inserted another chunk...... took 0.934 seconf\n",
      "inserted another chunk...... took 0.877 seconf\n",
      "inserted another chunk...... took 0.853 seconf\n",
      "inserted another chunk...... took 0.863 seconf\n",
      "inserted another chunk...... took 1.122 seconf\n",
      "inserted another chunk...... took 0.848 seconf\n",
      "inserted another chunk...... took 0.859 seconf\n",
      "inserted another chunk...... took 0.908 seconf\n",
      "inserted another chunk...... took 0.876 seconf\n",
      "inserted another chunk...... took 1.026 seconf\n",
      "inserted another chunk...... took 0.913 seconf\n",
      "inserted another chunk...... took 0.851 seconf\n",
      "inserted another chunk...... took 1.131 seconf\n",
      "inserted another chunk...... took 0.850 seconf\n",
      "inserted another chunk...... took 0.852 seconf\n",
      "inserted another chunk...... took 0.861 seconf\n",
      "inserted another chunk...... took 0.900 seconf\n",
      "inserted another chunk...... took 0.969 seconf\n",
      "inserted another chunk...... took 1.230 seconf\n",
      "inserted another chunk...... took 1.364 seconf\n",
      "inserted another chunk...... took 1.566 seconf\n",
      "inserted another chunk...... took 2.061 seconf\n",
      "inserted another chunk...... took 1.329 seconf\n",
      "inserted another chunk...... took 1.466 seconf\n",
      "inserted another chunk...... took 1.462 seconf\n",
      "inserted another chunk...... took 1.422 seconf\n",
      "inserted another chunk...... took 1.147 seconf\n",
      "inserted another chunk...... took 1.025 seconf\n",
      "inserted another chunk...... took 1.485 seconf\n",
      "inserted another chunk...... took 1.742 seconf\n",
      "inserted another chunk...... took 1.018 seconf\n",
      "inserted another chunk...... took 1.006 seconf\n",
      "inserted another chunk...... took 0.987 seconf\n",
      "inserted another chunk...... took 1.086 seconf\n",
      "inserted another chunk...... took 1.475 seconf\n",
      "inserted another chunk...... took 0.896 seconf\n",
      "inserted another chunk...... took 0.826 seconf\n",
      "inserted another chunk...... took 0.868 seconf\n",
      "inserted another chunk...... took 1.117 seconf\n",
      "inserted another chunk...... took 0.821 seconf\n",
      "inserted another chunk...... took 0.847 seconf\n",
      "inserted another chunk...... took 0.862 seconf\n",
      "inserted another chunk...... took 0.825 seconf\n",
      "inserted another chunk...... took 0.819 seconf\n",
      "inserted another chunk...... took 0.830 seconf\n",
      "inserted another chunk...... took 0.824 seconf\n",
      "inserted another chunk...... took 0.833 seconf\n",
      "inserted another chunk...... took 1.073 seconf\n",
      "inserted another chunk...... took 0.806 seconf\n",
      "inserted another chunk...... took 0.811 seconf\n",
      "inserted another chunk...... took 0.810 seconf\n",
      "inserted another chunk...... took 0.813 seconf\n",
      "inserted another chunk...... took 0.819 seconf\n",
      "inserted another chunk...... took 0.823 seconf\n",
      "inserted another chunk...... took 0.896 seconf\n",
      "inserted another chunk...... took 1.573 seconf\n",
      "inserted another chunk...... took 1.683 seconf\n",
      "inserted another chunk...... took 1.225 seconf\n",
      "inserted another chunk...... took 1.001 seconf\n",
      "inserted another chunk...... took 0.872 seconf\n",
      "inserted another chunk...... took 1.174 seconf\n",
      "inserted another chunk...... took 1.114 seconf\n",
      "inserted another chunk...... took 0.919 seconf\n",
      "inserted another chunk...... took 0.968 seconf\n",
      "inserted another chunk...... took 1.358 seconf\n",
      "inserted another chunk...... took 2.077 seconf\n",
      "inserted another chunk...... took 1.473 seconf\n",
      "inserted another chunk...... took 1.479 seconf\n",
      "inserted another chunk...... took 1.406 seconf\n",
      "inserted another chunk...... took 1.446 seconf\n",
      "inserted another chunk...... took 1.713 seconf\n",
      "inserted another chunk...... took 1.457 seconf\n",
      "inserted another chunk...... took 1.418 seconf\n",
      "inserted another chunk...... took 1.479 seconf\n",
      "inserted another chunk...... took 1.450 seconf\n",
      "inserted another chunk...... took 1.377 seconf\n",
      "inserted another chunk...... took 1.279 seconf\n",
      "inserted another chunk...... took 1.095 seconf\n",
      "inserted another chunk...... took 1.434 seconf\n",
      "inserted another chunk...... took 1.458 seconf\n",
      "inserted another chunk...... took 1.166 seconf\n",
      "inserted another chunk...... took 0.969 seconf\n",
      "inserted another chunk...... took 0.972 seconf\n",
      "inserted another chunk...... took 1.576 seconf\n",
      "inserted another chunk...... took 1.499 seconf\n",
      "inserted another chunk...... took 1.376 seconf\n",
      "inserted another chunk...... took 1.466 seconf\n",
      "inserted another chunk...... took 1.478 seconf\n",
      "inserted another chunk...... took 0.984 seconf\n",
      "inserted another chunk...... took 1.182 seconf\n",
      "inserted another chunk...... took 1.074 seconf\n",
      "inserted another chunk...... took 1.229 seconf\n",
      "inserted another chunk...... took 1.440 seconf\n",
      "inserted another chunk...... took 1.030 seconf\n",
      "inserted another chunk...... took 1.666 seconf\n",
      "inserted another chunk...... took 1.601 seconf\n",
      "inserted another chunk...... took 1.400 seconf\n",
      "inserted another chunk...... took 1.430 seconf\n",
      "inserted another chunk...... took 1.491 seconf\n",
      "inserted another chunk...... took 1.199 seconf\n",
      "inserted another chunk...... took 1.346 seconf\n",
      "inserted another chunk...... took 1.033 seconf\n",
      "inserted another chunk...... took 1.326 seconf\n",
      "inserted another chunk...... took 1.003 seconf\n",
      "inserted another chunk...... took 1.038 seconf\n",
      "inserted another chunk...... took 1.109 seconf\n",
      "inserted another chunk...... took 1.092 seconf\n",
      "inserted another chunk...... took 1.212 seconf\n",
      "inserted another chunk...... took 1.395 seconf\n",
      "inserted another chunk...... took 1.442 seconf\n",
      "inserted another chunk...... took 1.300 seconf\n",
      "inserted another chunk...... took 1.334 seconf\n",
      "inserted another chunk...... took 0.953 seconf\n",
      "inserted another chunk...... took 0.983 seconf\n",
      "inserted another chunk...... took 0.979 seconf\n",
      "inserted another chunk...... took 0.891 seconf\n",
      "inserted another chunk...... took 0.858 seconf\n",
      "inserted another chunk...... took 0.904 seconf\n",
      "inserted another chunk...... took 0.893 seconf\n",
      "inserted another chunk...... took 0.895 seconf\n",
      "inserted another chunk...... took 1.258 seconf\n",
      "inserted another chunk...... took 0.874 seconf\n",
      "inserted another chunk...... took 0.861 seconf\n",
      "inserted another chunk...... took 0.872 seconf\n",
      "inserted another chunk...... took 0.887 seconf\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36297/1785117550.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tpep_pickup_datetime\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpep_pickup_datetime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mget_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1072\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_currow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "while True:\n",
    "    \n",
    "    start_time = time()\n",
    "    \n",
    "    df = next(df_iterator)\n",
    "    \n",
    "    df[\"tpep_pickup_datetime\"] = pd.to_datetime(data.tpep_pickup_datetime)\n",
    "    df[\"tpep_dropoff_datetime\"] = pd.to_datetime(data.tpep_dropoff_datetime)\n",
    "    \n",
    "    df.to_sql(name = \"yellow_taxi_data\", con = engine ,if_exists= 'append')\n",
    "    \n",
    "    end_time = time()\n",
    "    \n",
    "    print(\"inserted another chunk...... took %.3f seconf\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e6ca62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
